{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/huy/BrainSegmentation\n"
     ]
    }
   ],
   "source": [
    "# Move to working directory\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"huytrnq/BrainSegmentation\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"huytrnq/BrainSegmentation\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository huytrnq/BrainSegmentation initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository huytrnq/BrainSegmentation initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='huytrnq', repo_name='BrainSegmentation', mlflow=True)\n",
    "\n",
    "import torch\n",
    "import torchio as tio\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torchio\")\n",
    "\n",
    "from utils.dataset import BrainMRIDataset, BrainMRISliceDataset\n",
    "from utils.predict import Predictor\n",
    "from utils.metric import dice_score_3d\n",
    "from utils.utils import export_to_nii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = './Data'\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 4\n",
    "NUM_WORKERS = 16\n",
    "DEVICE = 'mps' if torch.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforms\n",
    "val_transform = tio.Compose([\n",
    "    tio.RescaleIntensity((0, 1)),\n",
    "    tio.ZNormalization(),\n",
    "])\n",
    "## Dataset\n",
    "val_dataset = BrainMRIDataset(os.path.join(ROOT_DIR, 'val'), transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b744ad2984b4e128fcac9dcda07d98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0a6f106070423e9116ebbb26ee7e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8551b519ae204a5fab8ee4e86e31189e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc08f6dcea44550af37985ad7c2625f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model using MLflow\n",
    "predictor_patchs = []\n",
    "run_ids = ['94c24db36be94ebe947cdaf160c07409', '1bbaa5b686a1493bbe6a6fd83bfed272', 'dacc0d9816cc4ec5859f3e227a8bba9c', '5cabc56f7b374afd8b1c8ae12a190312']\n",
    "patch_sizes = [64, 64, 64, 128]\n",
    "for run_id, patch_size  in zip(run_ids, patch_sizes):\n",
    "    predictor_patch = Predictor(mlflow_model_uri=f\"runs:/{run_id}/model\", device=DEVICE, patch_size=patch_size)\n",
    "    predictor_patchs.append(predictor_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:34<00:00, 30.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice score: {0: 0.9976367950439453, 1: 0.9245912432670593, 2: 0.9475903511047363, 3: 0.943122386932373}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:35<00:00, 31.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice score: {0: 0.9976142644882202, 1: 0.923819363117218, 2: 0.9470298886299133, 3: 0.942984938621521}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:33<00:00, 30.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice score: {0: 0.997552752494812, 1: 0.9232271313667297, 2: 0.9455758333206177, 3: 0.941463828086853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice score: {0: 0.9977170825004578, 1: 0.9252330660820007, 2: 0.9494802355766296, 3: 0.9438269734382629}\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "masks = torch.stack([subject['mask'][tio.DATA] for subject in val_dataset], dim=0)\n",
    "\n",
    "overlaps = [32, 32, 32, 64]\n",
    "for predictor_patch, overlap in zip(predictor_patchs, overlaps):\n",
    "    patch_predictions = []\n",
    "    for subject in tqdm(val_dataset):\n",
    "        prediction = predictor_patch.predict_patches(subject, batch_size=BATCH_SIZE, overlap=overlap, proba=True)\n",
    "        patch_predictions.append(prediction)\n",
    "\n",
    "    # Stack all patch_predictions\n",
    "    patch_predictions = torch.stack(patch_predictions, dim=0)\n",
    "    predictions.append(patch_predictions)\n",
    "    dice = dice_score_3d(torch.argmax(patch_predictions, dim=1), masks.squeeze(1), num_classes=NUM_CLASSES)\n",
    "    print(f\"Dice score: {dice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Dice score: {0: 0.9977818727493286, 1: 0.928473949432373, 2: 0.9510732889175415, 3: 0.9468572735786438}\n"
     ]
    }
   ],
   "source": [
    "### Ensemble\n",
    "ensemble_predictions = torch.stack(predictions, dim=0)\n",
    "ensemble_predictions = ensemble_predictions.mean(dim=0)\n",
    "dice = dice_score_3d(torch.argmax(ensemble_predictions, dim=1), masks.squeeze(1), num_classes=NUM_CLASSES)\n",
    "print(f\"Ensemble Dice score: {dice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421348373095194"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(dice.values())[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Volume Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforms\n",
    "val_transform = tio.Compose([\n",
    "    tio.RescaleIntensity((0, 1)),\n",
    "    tio.ZNormalization(),\n",
    "])\n",
    "## Dataset\n",
    "val_dataset = BrainMRIDataset(os.path.join(ROOT_DIR, 'val'), transform=val_transform)\n",
    "val_loader = tio.SubjectsLoader(val_dataset, batch_size=1, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9277a3cb7c324f5d9fe90165b35235a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model using MLflow\n",
    "predictor_full = Predictor(mlflow_model_uri=\"runs:/1c98c526ea884b768e491a03985c8f22/model\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict\n",
    "predictions_full = predictor_full.predict_full_volume(val_loader, proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9966910481452942,\n",
       " 1: 0.8851995468139648,\n",
       " 2: 0.923554539680481,\n",
       " 3: 0.9096390008926392}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_score_3d(torch.argmax(predictions_full.squeeze(1), dim=1), masks.squeeze(1), num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforms\n",
    "test_transform = tio.Compose([\n",
    "    tio.RescaleIntensity((0, 1)),\n",
    "    tio.ZNormalization(),\n",
    "])\n",
    "## Dataset\n",
    "test_dataset = BrainMRIDataset(os.path.join(ROOT_DIR, 'test'), transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:59<00:00, 19.93s/it]\n",
      "100%|██████████| 3/3 [00:57<00:00, 19.08s/it]\n",
      "100%|██████████| 3/3 [01:02<00:00, 20.69s/it]\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.29s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "overlaps = [32, 32, 32, 64]\n",
    "for predictor_patch, overlap in zip(predictor_patchs, overlaps):\n",
    "    patch_predictions = []\n",
    "    for subject in tqdm(test_dataset):\n",
    "        prediction = predictor_patch.predict_patches(subject, batch_size=BATCH_SIZE, overlap=overlap, proba=True)\n",
    "        patch_predictions.append(prediction)\n",
    "\n",
    "    # Stack all patch_predictions\n",
    "    patch_predictions = torch.stack(patch_predictions, dim=0)\n",
    "    predictions.append(patch_predictions)\n",
    "\n",
    "### Ensemble\n",
    "ensemble_predictions = torch.stack(predictions, dim=0)\n",
    "ensemble_predictions = ensemble_predictions.mean(dim=0)\n",
    "ensemble_predictions = torch.argmax(ensemble_predictions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NIfTI file to ./results/IBSR_02.nii.gz\n",
      "Saved NIfTI file to ./results/IBSR_10.nii.gz\n",
      "Saved NIfTI file to ./results/IBSR_15.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for i, subject in enumerate(test_dataset):\n",
    "    affine = subject['image'].affine\n",
    "    spacing = subject['image'].spacing\n",
    "    name = subject['image'].path.name\n",
    "    export_to_nii(ensemble_predictions[i].numpy().astype(np.int16), f'./results/{name}', spacing, affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
