{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import torchio as tio\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torchio\")\n",
    "\n",
    "from utils.utils import train_3d, validate_3d\n",
    "from utils.vis import plot_mri\n",
    "from utils.dataset import BrainMRIDataset\n",
    "from utils.loss import DiceCrossEntropyLoss, DiceFocalLoss\n",
    "from models import UNet3D, AttentionUNet\n",
    "from monai.networks.nets import UNet, SegResNet, UNETR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = './Data'\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 300\n",
    "NUM_CLASSES = 4\n",
    "NUM_WORKERS=16\n",
    "DEVICE = 'mps' if torch.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchIO transformations for augmentation\n",
    "train_transform = tio.Compose([\n",
    "    tio.RandomAffine(scales=(0.9, 1.1)),\n",
    "    # tio.RandomElasticDeformation(num_control_points=(7, 7, 7), max_displacement=(4, 4, 4)),\n",
    "    # tio.RandomFlip(axes=(0, 1, 2)),\n",
    "    # tio.RandomBiasField(coefficients=(0.1, 0.3)),\n",
    "    tio.RescaleIntensity((0, 1))  # Normalize intensity to [0, 1]\n",
    "])\n",
    "\n",
    "val_transform = tio.Compose([\n",
    "    tio.RescaleIntensity((0, 1))  # Only normalize intensity for validation\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = BrainMRIDataset(os.path.join(ROOT_DIR, 'train'), transform=train_transform)\n",
    "val_dataset = BrainMRIDataset(os.path.join(ROOT_DIR, 'val'), transform=val_transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = tio.SubjectsLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = tio.SubjectsLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SegResNet(\n",
    "#     spatial_dims=3, \n",
    "#     init_filters=16, \n",
    "#     in_channels=1, \n",
    "#     out_channels=4, \n",
    "#     dropout_prob=None, \n",
    "#     act=('RELU', {'inplace': True}), \n",
    "#     norm=('GROUP', {'num_groups': 8}), \n",
    "#     norm_name='', \n",
    "#     num_groups=8, \n",
    "#     use_conv_final=True, \n",
    "#     blocks_down=(1, 2, 2, 4), \n",
    "#     blocks_up=(1, 1, 1)\n",
    "# )\n",
    "\n",
    "# model = UNet(\n",
    "#     spatial_dims=3,\n",
    "#     in_channels=1,\n",
    "#     out_channels=4,  \n",
    "#     channels=(16, 32, 64, 128, 256),\n",
    "#     strides=(2, 2, 2, 2),\n",
    "#     num_res_units=4,\n",
    "# )\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=4,  \n",
    "    channels=(32, 64, 128, 256, 512),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=4,\n",
    "    norm=\"instance\",  # Use Instance Normalization\n",
    "    dropout=0.2       # Add dropout\n",
    ")\n",
    "# model = UNETR(in_channels=1, out_channels=4, img_size=(256,128,258), feature_size=32, norm_name='batch')\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = train_dataset.calculate_class_weights_log(num_classes=4).to(DEVICE)\n",
    "# criterion = DiceCrossEntropyLoss(dice_weight=1.0, ce_weight=0.0, is_3d=True, class_weights=class_weights)\n",
    "criterion = DiceFocalLoss(alpha=[0.05, 0.5, 0.3, 0.3], gamma=2, is_3d=True, ignore_background=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_avg_dice = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_avg_loss, train_avg_dice, train_csf_dice, train_gm_dice, train_wm_dice = train_3d(model, train_loader, criterion, optimizer, DEVICE, epoch, EPOCHS, NUM_CLASSES)\n",
    "    val_avg_loss, val_avg_dice, val_csf_dice, val_gm_dice, val_wm_dice = validate_3d(model, val_loader, criterion, DEVICE, epoch, EPOCHS, NUM_CLASSES)\n",
    "    scheduler.step()\n",
    "    if val_avg_dice > best_avg_dice:\n",
    "        best_avg_dice = val_avg_dice\n",
    "        torch.save(model.state_dict(), 'best_model_3d.pth')\n",
    "        print(f'Best model saved with dice score: {best_avg_dice}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
